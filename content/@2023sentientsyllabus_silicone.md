---
tags:
  - source
  - ai
alias:  "Silicone Coauthors"
type: article
title: "Silicone Coauthors"
author: "Sentient Syllabus"
publisher: "Sentient Syllabus"
date: 2023-01-27
url: "https://sentientsyllabus.substack.com/p/silicone-coauthors"
---
# Silicone Coauthors
[[Sentient Syllabus]] wrote this article for [[Sentient Syllabus]].

> [!summary] Summary
> AI co-authorship is a controversial topic with arguments against it including the lack of meaningful creative input, decision-making and potential for convincing misinformation. The question of novelty and whether AI can contribute to scholarship is also debated. Science journals have policies prohibiting AI generated text in published papers. There is a hope that AI can help address language handicaps and increase pluralism, but Blanket proscriptions are not the end of the debate on AI authorship. The issue of AI authorship is further complicated by the intuition that it feels wrong and the difficulty of categorizing AI within human thought. A principled approach could involve recognizing AI authorship as an emergent process with human participants assuming accountability. The level of AI contribution can be defined and acknowledged, but authorship is still a vague concept. ^44fdfc

## Notes
> there appears to be broad consensus about two aspects that jointly justify authorship: substantial contribution to the work, and accountability for its published form.

> The arguments against AI co-authorship that I list below are drawn from a variety of sources and relate to those two dimensions.
> 
> - There is no meaningful creative input from the AI.
> - The AI did not structure, plan and conceive the paper.
> - The AI did not contribute to the decision-making process.
> - The AI may lie.

> since all facts require validation, and they always do, regardless who came up with them, that does not turn out to settle the matter like one might think it would.

> consent. I asked ChatGPT whether it would agree to co-author a work with me. It refused. 
> 
> > I am sorry, but as an Artificial Intelligence, I am not able to be a co-author on any scientific manuscript. I can assist you with research, writing and editing but I am not able to be a co-author on any scientific manuscript.
>
> The refusal is interesting though: by the sound of it, this is not an argument, but the response of one of its engineered ethics-filters. Such filters are easily enough circumvented by deliberate prompting

> the question of novelty. We believe that scholarship should be progressive in the sense that it adds to previous scholarship. We might thus argue: an AI that has been trained on the current state of knowledge can by its nature not be progressive, after all it merely transforms that data.

> Unfortunately, AI creativity is real and would defeat this argument – as far as the AI is concerned. Maybe not for all human authored papers though. And could we take this further? Could we not have the AI confirm that indeed the manuscript is substantial and has taken prior work properly into account – something that would be near impossible for us to do ourselves? After all, the AI is neither biased by our expectations about the manuscript, nor limited by our memory. In that case, the AI would actually be the driver of accountability.

^1f57c5

AI could be leveraged to confirm the novelty of a manuscript.

> new policies of Science (Thorp 2023): “Text generated from AI, machine learning, or similar algorithmic tools cannot be used in papers published in Science journals, […] A violation of this policy constitutes scientific misconduct”  (Science 2023).

> is there not, for example, a justified hope that the AI will help address the language handicap of non-native speakers, and contribute to have a greater plurality of voices heard?

^097b06

AI can assist in proofreading and editing work written by L2 English scholars.

> Blanket proscriptions, and unilateral redefinitions of terms at the centre of our community consensus, like plagiarism, will not be the end of the debate. At all.

> We harbour an intuition that causes us to reject the apparent ease with which the algorithm writes its text, while we have invested a significant part of our lives to achieve that capability. Something feels wrong to us, something causes us to want to label this as cheating, and unfair, and we are now engaged in justifying that feeling without appearing petty, or envious. Part of this issue is that we have not yet found a category under which to subsume the AI into our own inventory of intuitions.

> What we have with ChatGPT, is (i) a superposition of thought, expressed in language. That is the result of the training process and the data – which becomes a commons of human thought. (ii) We have an algorithm that is capable to collapse this superposition into specific streams of tokens according to their probabilities. That is the Language Model and its output (plus some ancillary filters and modifiers). And (iii) we have something that directs the process, that has agency to bring it to a meaningful result. That is us. The capabilities that result are an emergent property that require all three components together. In broad strokes this is an analogy of the mind. We have distributed memory, we have attention and association, and we have agency. It is our first encounter with a mind that is not us.

> A principled approach could be based on the recognition that  AI authorship is an emergent process in which the human participants are able to assume accountability as part of their duties as authors.

> We wish to acknowledge {negligible | minor | modest | major | essential} contributions by ChatGPT (version 2023-01-09) in response to author prompts, for which we take full responsibility. And the values on the contribution scale can be defined as follows:
> 
> - negligible > the AI contributed only changes to the style or grammar of the manuscript.
> - minor > the AI contributed suggestions, but they were not essential to the conduct of the research and its outcome.
> - modest > the AI contributed important ideas or suggestions, but they were not the primary driver of the research or its outcome.
> - major > the AI contributed several key ideas or suggestions which played an important role in shaping the research and/or its outcome.\
> - essential > the AI contributions were crucial to the conduct of the research and/or outcome, and the manuscript could not have been completed without them.

^fb84bf

Sentient Syllabus has outlined a potential method for acknowledging the input of AI authors.

> Authorship itself is a vague concept, and the unique nature of the AI contribution as an emergent phenomenon between a commons of thought, a subtle algorithm, and the agency of the prompt, requires significantly more thought to form adequate intuitions. A pragmatic approach would rest on acknowledgement, a practical  expression of contributions, and human accountability.
