---
tags:
  - source
  - ai
  - writing
  - labor
alias:  "ChatGPT Is Dumber Than You Think"
type: article
title: "ChatGPT Is Dumber Than You Think"
author: "Ian Bogost"
publisher: "The Atlantic"
date: 2022-12-07
url: "https://www.theatlantic.com/technology/archive/2022/12/chatgpt-openai-artificial-intelligence-writing-ethics/672386/"
---
# ChatGPT Is Dumber Than You Think
[[Ian Bogost]] wrote this article for [[The Atlantic]].

> [!summary] Summary
> [[Ian Bogost]] doubts the fears surrounding AI-generated text because of the lack of creativity.

## Notes
> it does not have the ability to truly comprehend the meaning behind those words. This means that any responses it generates are likely to be shallow and lacking in depth and insight

^0b4917

I wonder, though, if at some point this won't matter. Knowledge is encoded in language, it might be the case that a language model and knowledge model are ultimately synonymous.

What is really the difference between language and knowledge? Sapir-Whorf hypothesis meets chatGPT

> John Warner, the author of the book Why They Can’t Write, has been railing against the five-paragraph essay for years and wrote a Twitter thread about how ChatGPT reflects this rules-based, standardized form of writing: “Students were essentially trained to produce imitations of writing,” he tweeted. The AI can generate credible writing, but only because writing, and our expectations for it, has become so unaspiring.

^f78729

The five-paragraph essay has been criticized for quite some time.

> They do offer those and other domains a new instrument—that’s really the right word for it—with which to play with an unfathomable quantity of textual material. ... They offer an interface into the textual infinity of digitized life, an otherwise impenetrable space that few humans can use effectively in the present.

^b035e5

It might be best to think of LLMs as a language query tool. This will likely get more interesting when models can be trained in a domain-specific way.

> the bot also knew, with reasonable accuracy, why it was wrong.

^c20881

The job of an LLM is to produce content no matter what, even when it knows it's inaccurate or not in the correct format.

> To accomplish something in the world often boils down to mustering a set of stock materials into the expected linguistic form. That’s true for Google or Amazon, where searches for window coverings or anything else now fail most of the time, requiring time-consuming, tightrope-like finagling to get the machinery to point you in even the general direction of an answer. But it’s also true for student essays, thank-you notes, cover letters, marketing reports, and perhaps even medieval lais (insofar as anyone would aim to create one). We are all faking it with words already. We are drowning in an ocean of content, desperate for form’s life raft.

