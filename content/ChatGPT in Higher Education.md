---
date: 2023-01-18
publish: true
---

Despite the valid concerns of language AI models like ChatGPT, there are a number of benefits for students and teachers alike.

ChatGPT is a _language model_ and not a _knowledge model_; its goal is to predict the next word, even if it is nonsense or illogical. This also means that it cannot provide representations of knowledge, visual or otherwise (i.e., mind maps) and cannot engage in critical argumentation (i.e., debates); at least yet. It is doubtful whether it ever could be, since it would have trouble distinguishing factual information from false information. The emergence of such powerful AI has raised a lot of serious questions in a wide range of fields. As we learn about and discuss these issues, it is important to avoid anthropomorphizing AI tools like chatGPT to put what it produces into perspective ([[2022-12-18 Watkins|2022 Watkins]]). Treating it like a human makes it tempting to see the output as genuine knowledge, but this is not the case. Like other forms of artificial intelligence, ChatGPT threatens humanity with job obsolescence. Some writing jobs will be more easily replaced by these language models than others. Writing that does not involve critical thinking or interpretations of information are still believed to be relatively safe, however ([[@2015shiller_what|2015 Shiller]], summarizing 2004 Levy & Murnane).

These AI language models have multiple impacts on education, particularly in writing, rhetoric, and composition. Recently, the New York City public school system decided to ban ChatGPT from their networks ([[2023-01-06 Lukpat|2023 Lukpat]]), with other districts considering doing the same. The two main threads being discussed are its disruption (or boon) to academic dishonesty, and a questioning of the value of educators.

Speaking first to the issue of academic dishonesty, students can use AI to generate unique texts for an assignment that do not reflect their actual skills. These texts would be able to avoid detection through services like current versions of TurnItIn. The good news is that there has been rapid development in tools to detect AI generated content. Two such tools being the [GPT-2 Output Detector model](https://openai-openai-detector.hf.space/) , which uses a model based on older (GPT-2) generated texts, and [GPTZero](https://etedward-gptzero-main-zqgfwb.streamlit.app/) ([[2023 Svurluga|2023 Svurluga]]), is seeing more success in detecting the GPT-3 content generated by ChatGPT. However, these detection models could easily become outclassed by newer developments, resulting in an AI arms race.

In addition to the detection tools, OpenAI (the developer of ChatGPT and the GPT-3 model) plans to implement watermark features in the text it produces to reduce the impact of AI-generated text on academic dishonesty and propaganda. Experts in the field note that these watermarking techniques being discussed are not as robust as we'd expect and can be easily removed ([[2022-12-10 Wiggers|2020 Wiggers]]; [[2022-12-30 Montti|2022 Montti]]). Equally concerning, is that OpenAI is not the only one developing these large language models. It's possible other players in the AI game, such as [Stability Diffusion](https://stability.ai/) could release their own competing chatbots, and may or may not also include watermarking features. So far, both detection and watermarking do not look promising. One thing to note is that at least currently, ChatGPT does not cite sources, which is a common requirement for student essays. However, there are calls to implement this and it has been getting attention ([[2022-12-10 Wiggers|2020 Wiggers]]).

The second issue is that it calls into question the importance of learning composition and rhetorical skills if those specific skills can be automated and jobs based on those skills are likely to be automated. We can already see that advanced critical thinking skills will become even more important as AI gets better at generating content ([[2022-12-18 Watkins|2022 Watkins]]). Ryan Watkins, Professor of Educational Technology Leadership, and Human-Technology Collaboration at George Washington University urges that we "focus on the value [we] offer students as their instructor."

We can mitigate disruption from these tools by making learning objectives more clear to students. When students have a better understanding of the goals in a course, the work that is necessary to get there, and how assignments align with those goals, they are more willing to put in the labor of learning. (1975 Berte; 1986 Knowles; 1996 Anderson et al.; [[@2022inoue_labor|2022 Inoue]]) Now is a great time to explore alternative methods of grading students that focus less on the final outcome and more on the goals and labor of learning.

We can also bring students into the conversation about the ethics of using AI and the value of human instruction ([[2022-12-18 Watkins|2022 Watkins]]). We understand that learning occurs when a person engages in the process of the subject of their learning, but "learning" can so easily be confused with submitting a finished paper for a grade ([[@2022inoue_labor|2022 Inoue]]).

Still, current news is bracing us for a disruption in education from AI. Bloomburg ([[2022-12-14 Stone|2022 Stone]]) presents a panicked perspective that warns us that higher education won't be able to keep up when AI can make knowledge instantaneous for students, but there are two points I take issue with. First, the slow pace of innovation in higher education is not the fault of AI language models; it was a weak point that has been highlighted. Secondly, as I said earlier, ChatGPT and other models are language models and not knowledge models. Therefore, they cannot and are not intended to be able to represent knowledge or apply critical lenses to data. The only reason it can "wax on about morality in Shakespeare's final play" is because that has been done a million times already and the model was able to use that data on what has been said by students and scholars and essentially predict an essay. Higher education is worried that students using ChatGPT will not strengthen their critical thinking skill, but by giving the same assignments again and again, weren't we already doing that?

Watkins suggests several adjustments to assignments that actually require students to use ChatGPT critically. In fact, it can have several benefits to students and teachers alike. Inviting AI into the classroom can give students an opportunity to discuss the personal and social ethical consequences of AI; that is, the affect on learning when one doesn't fully engage in the subject, and the potential of AI taking propaganda and misinformation to new levels. For teachers, and specifically English language teachers, ChatGPT offers the ability to generate countless examples of texts. ChatGPT can differentiate text output based on language proficiency. By including mentions of CEFR levels, it can can change the difficulty of the language output. It can even include grammar mistakes on request. It can also produce topical content in a variety of styles of prose, poetry, etc. In addition, ChatGPT can also be an accessibility tool for people with dyslexia and developmental language disorders (2023 Alcántara). Even better, U.S. copyright law has already set a precedent that AI-generated art cannot be copyrighted ([[2022-03-24 Recker|2022 Recker]]), which would make all of this educational content free of any license regardless of the company that owns the AI models.

For better or worse, high quality AI tools are here generating text, audio, and video. I feel that the best approach would be to learn and teach others how to use them critically.

* * *
## References

- 1975 Berte: _Individualizing Education through Contract Learning_
- 1986 Knowles: _Using Learning Contracts_
- 1996 Anderson et al.: _Learning Contracts_
- 2004 Levy & Murnane: _The New Division of Labor: How Computers Are Creating the Next Job Market_
- [2015 Shiller](https://www.nytimes.com/2015/05/24/upshot/what-to-learn-in-college-to-stay-one-step-ahead-of-computers.html): _What to Learn in College to Stay One Step Ahead of Computers_
- [2020 Wiggers](https://www.searchenginejournal.com/chatgpt-watermark/475366/)
- 2022 Inoue: _Labor-based grading contracts: Building equity and inclusive in the compassionate writing classroom_
- [2022 Montii](https://www.searchenginejournal.com/chatgpt-watermark/475366/): _How The ChatGPT Watermark Works And Why It Could Be Defeated_
- [2022 Recker](https://www.smithsonianmag.com/smart-news/us-copyright-office-rules-ai-art-cant-be-copyrighted-180979808/): _U.S. Copyright Office Rules A.I. Art Can’t Be Copyrighted_
- [2022 Stone](https://www.bloomberg.com/news/newsletters/2022-12-14/anti-cheating-education-software-braces-for-chatgpt): _Anti-Cheating Education Software Braces for AI Chatbots_
- [2022 Watkins](https://medium.com/@rwatkins_7167/updating-your-course-syllabus-for-chatgpt-965f4b57b003): _Update Your Course Syllabus for chatGPT_
- [2023 Alcántara](https://www.wsj.com/articles/is-it-human-or-ai-new-tools-help-you-spot-the-bots-11673356404): _Is It Human or AI? New Tools Help You Spot the Bots_
- [2023 Lukpat](https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-public-schools-over-concerns-about-cheating-learning-development-11673024059): _ChatGPT Banned in New York City Public Schools Over Concerns About Cheating, Learning Development_
- [2023 Svurluga](https://www.washingtonpost.com/education/2023/01/12/gptzero-chatgpt-detector-ai/): _Was that essay written by AI? A student made an app that might tell you._